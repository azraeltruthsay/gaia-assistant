services:
  campaign_llm:
    build: .
    ports:
      - "7860:7860"
    volumes:
      - ./projects:/app/projects:rw
      - ./personalities:/app/personalities:rw
      - ./shared:/app/shared:rw
      - ../gaia-models/Hermes-3-Llama-3.2-3B.Q4_K_M.gguf:/app/model.gguf:ro
      - ../gaia-models/qwen2.5-coder-14b-instruct-q2_k.gguf.gguf:/app/model-c.gguf:ro
      - ./logs:/app/logs:rw
    environment:
      # Model paths
      MODEL_PATH: /app/model.gguf
      CODE_MODEL_PATH: /app/model-c.gguf
      DEFAULT_PERSONALITY_FILE: /app/personalities/default_personality.json
      PERSONALITIES_PATH: /app/personalities
      # Now using project-relative paths
      DATA_PATH: /app/projects/dnd-campaign/core-documentation
      RAW_DATA_PATH: /app/projects/dnd-campaign/raw-data
      OUTPUT_PATH: /app/projects/dnd-campaign/converted_raw
      VECTOR_DB_PATH: /app/shared/chroma_db
      PROJECTS_DIR: /app/shared
      N_GPU_LAYERS: 0
      N_THREADS: 8
      N_BATCH: 128
      N_CTX: 2048
      SKIP_TTS_SELECTION: 'true'
      ENABLE_TTS: 'true'
      FLASK_ENV: 'production'
      DEBUG_MODE: 'false'
      PORT: 7860
      SECRET_KEY: Thanks_GPT_123!!!
      EMBEDDING_MODEL: all-mpnet-base-v2
      # Background Processor Configuration
      BG_IDLE_THRESHOLD: 300
      BG_LONG_IDLE_THRESHOLD: 1800
      BG_ENABLE_LORA: 'false'
      BG_OVERNIGHT: 'true'
      BG_OVERNIGHT_START: 22
      BG_OVERNIGHT_END: 6
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: '6'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
